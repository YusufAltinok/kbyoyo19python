{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sınıflandırma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir önceki notebook'ta sınıflandırma için Logistic Regression modelini gördük. Scikit-learn kütüphanesinde daha birçok sınıflandırma algoritması mevcut. Zaman kısıtından ötürü sadece bir kaçına bakacağız ancak alıştıktan sonra başka algoritmaları kullanmak kolay. Isınma turu olarak *Naive Bayes*, *Decision Tree*, *Multi Layer Perceptron* algoritmalarına hızlıca bakacağız. Daha sonrasında *Support Vector Machine* ve *Random Forest* algoritmalarının kullanımını göreceğiz. Bunu, öznitelik çıkartmak izleyecek.\n",
    "\n",
    "## Iris Veri Seti Üzerinde Hızlıca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ortamı hazırlayalım\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "seed = int(time.time())\n",
    "\n",
    "\n",
    "def quickTest(X, y, clf):\n",
    "    #Her algoritma aynı veri setini görsün diye\n",
    "    np.random.seed(seed)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.4, stratify=y)\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    ypred = clf.predict(Xtest)\n",
    "    print(type(clf).__name__ + ': ', accuracy_score(ypred,ytest))\n",
    "    return type(clf).__name__, accuracy_score(ypred,ytest)\n",
    "\n",
    "\n",
    "def plotConfusionMatrix(mat):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(mat)\n",
    "\n",
    "    # Değerleri grafik üzerinde göstermek\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            text = plt.text(j, i, mat[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "        \n",
    "    plt.xlabel('gerçek sınıf')\n",
    "    plt.ylabel('tahminlenen sınıf');\n",
    "\n",
    "iris_data = datasets.load_iris()\n",
    "X = iris_data['data']\n",
    "y = iris_data['target']\n",
    "\n",
    "names = ['']*9\n",
    "accuracies = [0]*9\n",
    "\n",
    "names[0], accuracies[0] = quickTest(X,y,LogisticRegression(multi_class = 'auto',\n",
    "                                                           solver ='lbfgs', \n",
    "                                                           max_iter = 1000))\n",
    "names[1], accuracies[1] = quickTest(X,y,MultinomialNB())\n",
    "names[2], accuracies[2] = quickTest(X,y,GaussianNB())\n",
    "names[3], accuracies[3] = quickTest(X,y,DecisionTreeClassifier())\n",
    "names[4], accuracies[4] = quickTest(X,y,KNeighborsClassifier())\n",
    "names[5], accuracies[5] = quickTest(X,y,RandomForestClassifier(n_estimators = 5))\n",
    "names[6], accuracies[6] = quickTest(X,y,LinearSVC(max_iter=10000))\n",
    "names[7], accuracies[7] = quickTest(X,y,SVC(gamma='auto'))\n",
    "names[8], accuracies[8] = quickTest(X,y,MLPClassifier(hidden_layer_sizes=(20, ),\n",
    "                                                      max_iter=10000))\n",
    "\n",
    "plt.bar(list(range(9)),accuracies)\n",
    "plt.xticks(list(range(9)),names,rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentetik 2 boyutlu veride sınıflandırma algoritmalarının karşılaştırması: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Yazısı Rakam Veri Seti\n",
    "\n",
    "Biraz daha entersan bir probleme bakalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8x8 çözünürlükte 1797 adet resim var. Daha yüksek çözünürlüklü ve daha kalabalık bir el yazısı rakam veri seti için \"MNIST data set\" kelimeleri ile arama yapabilirsiniz. Hazır scikit-learn ile geldiği için ufak versiyonunu kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#0dan 9a toplam 10 adet rakam var. Örnek bir kısmını çizdirelim\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Girdilerimiz 3 boyutlu ancak scikit-learn 2 boyutlu istiyor. Çözüm olarak piksel değerlerini 8x8 bir matristen, 64lük bir vektöre çevireceğiz. Scikit-learn bizim için çoktan yapmış."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits['data']\n",
    "y = digits['target']\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hem doğrusal, hem de çekirdek SVM öğrenelim. Her iki tür SVM'in `C` ile belirttiğimiz regülarizasyon parametresi var. Çekirdek SVM'in birden fazla hiperparametresi var. Örneğin çekirdek türü ve bu türe göre gelen ek parametreler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.4, \n",
    "                                                stratify=y)\n",
    "cv=StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "ksvmParams = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "             'kernel': ['poly', 'rbf'],\n",
    "             'degree': [1,2,3,4,5]}\n",
    "\n",
    "ksvc = RandomizedSearchCV(SVC(gamma='scale'), ksvmParams, cv=cv, n_iter=20, iid=True)\n",
    "ksvc.fit(Xtrain,ytrain)\n",
    "ypred = ksvc.predict(Xtest)\n",
    "print('Seçilen Çekirdek: ', ksvc.best_estimator_.kernel)\n",
    "print('Seçilen C: ', ksvc.best_estimator_.C)\n",
    "print('Kernel SVM: ', accuracy_score(ypred,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verinin bir alt kümesine bakalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "test_images = Xtest.reshape(-1, 8, 8)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(test_images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(ypred[i]),\n",
    "            transform=ax.transAxes,\n",
    "            color='green' if (ytest[i] == ypred[i]) else 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hata Matrisine bakalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ypred,ytest)\n",
    "plotConfusionMatrix(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kıyaslamak adına MLP, GaussianNB ve Decision Tree deneyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsToTestMLP = {'hidden_layer_sizes': [(30, ), (10, ), (5,), (20,10)]}\n",
    "mlp =  GridSearchCV(MLPClassifier(max_iter=10000), paramsToTestMLP, cv=cv, iid=True)\n",
    "mlp.fit(Xtrain,ytrain)\n",
    "ypred = mlp.predict(Xtest)\n",
    "print('Seçilen Saklı Katman: ', mlp.best_estimator_.hidden_layer_sizes)\n",
    "print('MLP: ', accuracy_score(ypred,ytest))\n",
    "mat = confusion_matrix(ypred,ytest)\n",
    "plotConfusionMatrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gmb = GaussianNB()\n",
    "gmb.fit(Xtrain, ytrain)\n",
    "ypred = gmb.predict(Xtest)\n",
    "print('GaussianMB: ', accuracy_score(ypred,ytest))\n",
    "mat = confusion_matrix(ypred,ytest)\n",
    "plotConfusionMatrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "dtParams = {\"max_depth\": [5, None],\n",
    "            \"max_features\": sp_randint(1, 11),\n",
    "            \"min_samples_split\": sp_randint(2, 11),\n",
    "            \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "dt = RandomizedSearchCV(DecisionTreeClassifier(), dtParams, cv=cv, n_iter=25, iid=True)\n",
    "dt.fit(Xtrain,ytrain)\n",
    "ypred = dt.predict(Xtest)\n",
    "print('Seçilenler: ', dt.best_estimator_.max_depth,dt.best_estimator_.max_features,\n",
    "      dt.best_estimator_.min_samples_split,dt.best_estimator_.criterion)\n",
    "print('Decision Tree: ', accuracy_score(ypred,ytest))\n",
    "mat = confusion_matrix(ypred,ytest)\n",
    "plotConfusionMatrix(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree çok iyi sonuç vermedi. Bir de RandomForest algoritmasına bakalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "rfParams = {\"max_depth\": [5, None],\n",
    "            \"max_features\": sp_randint(1, 11),\n",
    "            \"min_samples_split\": sp_randint(2, 11),\n",
    "            \"bootstrap\": [True, False],\n",
    "            \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rf = RandomizedSearchCV(RandomForestClassifier(n_estimators=10), rfParams, cv=cv, n_iter=25, iid=True)\n",
    "rf.fit(Xtrain,ytrain)\n",
    "ypred = rf.predict(Xtest)\n",
    "print('Seçilenler: ', rf.best_estimator_.max_depth,rf.best_estimator_.max_features,\n",
    "      rf.best_estimator_.min_samples_split,rf.best_estimator_.bootstrap,rf.best_estimator_.criterion)\n",
    "print('Random Forest: ', accuracy_score(ypred,ytest))\n",
    "mat = confusion_matrix(ypred,ytest)\n",
    "plotConfusionMatrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
